echo "words = 'the quick brown fox jumps over the\
        lazy dog the quick brown fox jumps over the lazy dog'
sc = SparkContext()
seq = words.split()
data = sc.parallelize(seq)
counts = data.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b).collect()
dict(counts)
sc.stop()"

sparkmaster=`kubectl get pods | awk '{if($1 ~ /master/) print $1}'`


kubectl exec $sparkmaster  -it pyspark
